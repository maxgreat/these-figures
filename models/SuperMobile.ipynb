{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "#torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "#jupyter\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "#os\n",
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "\n",
    "#math\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "    channels_per_group = num_channels // groups\n",
    "    x = x.view(batchsize, groups, channels_per_group, height, width) #add a new dimension\n",
    "    \n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    return x.view(batchsize, -1, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_groups=32, eps=1e-5):\n",
    "        super(GroupNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(1,num_features,1,1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1,num_features,1,1))\n",
    "        self.num_groups = num_groups\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        N,C,H,W = x.size()\n",
    "        G = self.num_groups\n",
    "        assert C % G == 0\n",
    "\n",
    "        x = x.view(N,G,-1)\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True)\n",
    "\n",
    "        x = (x-mean) / (var+self.eps).sqrt()\n",
    "        x = x.view(N,C,H,W)\n",
    "        return x * self.weight + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class IdentityBloc(nn.Module):\n",
    "    def __init__(self,input_channels, output_channels, nb_groups, nb_frames=1):\n",
    "        super(IdentityBloc, self).__init__()\n",
    "        self.conv3 = nn.Conv2d(input_channels*nb_frames, input_channels*nb_frames, kernel_size=3, stride=1, padding=1, groups=nb_groups*nb_frames)\n",
    "        self.bn3 = nn.BatchNorm2d(input_channels*nb_frames)\n",
    "        self.conv1 = nn.Conv2d(input_channels*nb_frames, output_channels*nb_frames, kernel_size=1, stride=1, padding=0, groups=nb_frames)\n",
    "        self.bn1 = nn.BatchNorm2d(output_channels*nb_frames)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        right = self.relu(self.bn3(self.conv3(x)))\n",
    "        right = self.relu(self.bn1(self.conv1(right)))\n",
    "        return x.add(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DownBloc(nn.Module):\n",
    "    def __init__(self,input_channels, output_channels, nb_groups, nb_frames=1, shuffle=False):\n",
    "        super(DownBloc, self).__init__()\n",
    "        self.nb_groups = nb_groups\n",
    "        self.shuffle   = shuffle\n",
    "        self.conv3     = nn.Conv2d(input_channels*nb_frames, input_channels*nb_frames, \n",
    "                                   kernel_size=3, stride=2, padding=1, groups=nb_groups*nb_frames)\n",
    "        self.bn3       = nn.BatchNorm2d(input_channels*nb_frames)\n",
    "        self.conv1     = nn.Conv2d(input_channels*nb_frames, output_channels*nb_frames, kernel_size=1, stride=1, padding=0, groups=nb_frames)\n",
    "        self.bn1       = nn.BatchNorm2d(output_channels*nb_frames)\n",
    "        self.relu      = nn.ReLU()\n",
    "        self.pool      = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        left = self.pool(x)\n",
    "        right = self.relu(self.bn3(self.conv3(x)))\n",
    "        if self.shuffle:\n",
    "            right = channel_shuffle(right, self.nb_groups)\n",
    "        right = self.relu(self.bn1(self.conv1(right)))\n",
    "        return torch.cat( (left, right), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FusionBloc(nn.Module):\n",
    "    def __init__(self,input_channels, output_channels, nb_frames=1):\n",
    "        super(FusionBloc, self).__init__()\n",
    "        self.conv1     = nn.Sequential(\n",
    "                            nn.Conv2d(input_channels*nb_frames, output_channels, kernel_size=1, stride=1, padding=0),\n",
    "                            nn.BatchNorm2d(output_channels),\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DenseMobile(nn.Module):\n",
    "    def __init__(self, in_channel=3, nb_frames=1, num_classes=6, first_group=True):\n",
    "        super(DenseMobile, self).__init__()\n",
    "        if first_group:\n",
    "            self.blocStart = DownBloc(in_channel, 32-in_channel, in_channel, nb_frames=nb_frames) #224x224x3 -> 112x112x32\n",
    "        else:\n",
    "            self.blocStart = nn.Sequential(\n",
    "                            nn.Conv2d(in_channel, 32, kernel_size=3, stride=2, padding=1),\n",
    "                            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "                        )\n",
    "        self.iddown = nn.Sequential(\n",
    "                        IdentityBloc(32, 32, 32, nb_frames=nb_frames), # -> 112x112x32\n",
    "                        DownBloc(32,32,32, nb_frames=nb_frames), # -> 56x56x64\n",
    "                        IdentityBloc(64,64,64, nb_frames=nb_frames), # -> 56x56x128\n",
    "                        DownBloc(64, 192, 64, nb_frames=nb_frames), # -> 28x28x256\n",
    "                        FusionBloc(256,256, nb_frames),\n",
    "                        IdentityBloc(256,256, 256), # -> 28x28x256\n",
    "                        DownBloc(256, 256, 256), # -> 14x14x512\n",
    "                        IdentityBloc(512, 512, 512)\n",
    "                    )\n",
    "        \n",
    "\n",
    "        self.end = nn.Sequential(\n",
    "                        DownBloc(512,512,512), # -> 7x7x1024\n",
    "                        nn.AvgPool2d(kernel_size=7, padding=0, stride=1), #3x3\n",
    "        )\n",
    "        self.classif = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocStart(x)\n",
    "        x = self.iddown(x)\n",
    "        #x1 = self.dense(x)\n",
    "        #x.add(x1)\n",
    "        x = self.end(x)\n",
    "        return self.classif(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenseMobileF1(nn.Module):\n",
    "    def __init__(self, num_classes=6, first_group=True):\n",
    "        super(DenseMobileF1, self).__init__()\n",
    "        \n",
    "        self.blocStart = DownBloc(9, 32-9, 9) #224x224x3 -> 112x112x32\n",
    "\n",
    "        self.iddown = nn.Sequential(\n",
    "                        IdentityBloc(32, 32, 32), # -> 112x112x32\n",
    "                        DownBloc(32,32,32), # -> 56x56x64\n",
    "                        IdentityBloc(64,64,64), # -> 56x56x128\n",
    "                        DownBloc(64, 192, 64), # -> 28x28x256\n",
    "                        IdentityBloc(256,256, 256), # -> 28x28x256\n",
    "                        DownBloc(256, 256, 256), # -> 14x14x512\n",
    "                        IdentityBloc(512, 512, 512)\n",
    "                    )\n",
    "        self.end = nn.Sequential(\n",
    "                        DownBloc(512,512,512), # -> 7x7x1024\n",
    "                        nn.AvgPool2d(kernel_size=7, padding=0, stride=1), #3x3\n",
    "        )\n",
    "        self.classif = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocStart(x)\n",
    "        x = self.iddown(x)\n",
    "        #x1 = self.dense(x)\n",
    "        #x.add(x1)\n",
    "        x = self.end(x)\n",
    "        return self.classif(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseMobileF2(nn.Module):\n",
    "    def __init__(self, num_classes=6, first_group=True):\n",
    "        super(DenseMobileF2, self).__init__()\n",
    "        \n",
    "        self.blocStart = DownBloc(3, 32-3, 3, nb_frames=3) #224x224x3 -> 112x112x32\n",
    "\n",
    "        self.iddown = nn.Sequential(\n",
    "                        IdentityBloc(32, 32, 32, nb_frames=3), # -> 112x112x32\n",
    "                        DownBloc(32,32,32, nb_frames=3), # -> 56x56x64\n",
    "                        FusionBloc(64*3,64),\n",
    "                        IdentityBloc(64,64,64), # -> 56x56x128\n",
    "                        DownBloc(64, 192, 64), # -> 28x28x256\n",
    "                        #FusionBloc(256,256),\n",
    "                        IdentityBloc(256,256, 256), # -> 28x28x256\n",
    "                        DownBloc(256, 256, 256), # -> 14x14x512\n",
    "                        IdentityBloc(512, 512, 512)\n",
    "                    )\n",
    "        self.end = nn.Sequential(\n",
    "                        DownBloc(512,512,512), # -> 7x7x1024\n",
    "                        nn.AvgPool2d(kernel_size=7, padding=0, stride=1), #3x3\n",
    "        )\n",
    "        self.classif = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocStart(x)\n",
    "        x = self.iddown(x)\n",
    "        #x1 = self.dense(x)\n",
    "        #x.add(x1)\n",
    "        x = self.end(x)\n",
    "        return self.classif(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseMobileF4(nn.Module):\n",
    "    def __init__(self, num_classes=6, first_group=True):\n",
    "        super(DenseMobileF4, self).__init__()\n",
    "        \n",
    "        self.blocStart = DownBloc(3, 32-3, 3, nb_frames=3) #224x224x3 -> 112x112x32\n",
    "\n",
    "        self.iddown = nn.Sequential(\n",
    "                        IdentityBloc(32, 32, 32, nb_frames=3), # -> 112x112x32\n",
    "                        DownBloc(32,32,32, nb_frames=3), # -> 56x56x64\n",
    "                        IdentityBloc(64,64,64, nb_frames=3), # -> 56x56x128\n",
    "                        DownBloc(64, 192, 64, nb_frames=3), # -> 28x28x256\n",
    "                        #FusionBloc(256,256),\n",
    "                        IdentityBloc(256,256, 256, nb_frames=3), # -> 28x28x256\n",
    "                        DownBloc(256, 256, 256, nb_frames=3), # -> 14x14x512\n",
    "                        FusionBloc(512*3, 512),\n",
    "                        IdentityBloc(512, 512, 512)\n",
    "                    )\n",
    "        self.end = nn.Sequential(\n",
    "                        DownBloc(512,512,512), # -> 7x7x1024\n",
    "                        nn.AvgPool2d(kernel_size=7, padding=0, stride=1), #3x3\n",
    "        )\n",
    "        self.classif = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocStart(x)\n",
    "        x = self.iddown(x)\n",
    "        #x1 = self.dense(x)\n",
    "        #x.add(x1)\n",
    "        x = self.end(x)\n",
    "        return self.classif(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseMobileF5(nn.Module):\n",
    "    def __init__(self, num_classes=6, first_group=True):\n",
    "        super(DenseMobileF5, self).__init__()\n",
    "        \n",
    "        self.blocStart = DownBloc(3, 32-3, 3, nb_frames=3) #224x224x3 -> 112x112x32\n",
    "\n",
    "        self.iddown = nn.Sequential(\n",
    "                        IdentityBloc(32, 32, 32, nb_frames=3), # -> 112x112x32\n",
    "                        DownBloc(32,32,32, nb_frames=3), # -> 56x56x64\n",
    "                        IdentityBloc(64,64,64, nb_frames=3), # -> 56x56x128\n",
    "                        DownBloc(64, 192, 64, nb_frames=3), # -> 28x28x256\n",
    "                        #FusionBloc(256,256),\n",
    "                        IdentityBloc(256,256, 256, nb_frames=3), # -> 28x28x256\n",
    "                        DownBloc(256, 256, 256, nb_frames=3), # -> 14x14x512\n",
    "                        IdentityBloc(512, 512, 512, nb_frames=3)\n",
    "                    )\n",
    "        self.end = nn.Sequential(\n",
    "                        DownBloc(512,512,512, nb_frames=3), # -> 7x7x1024\n",
    "                        nn.AvgPool2d(kernel_size=7, padding=0, stride=1), #3x3\n",
    "        )\n",
    "        self.classif = nn.Linear(1024*3, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocStart(x)\n",
    "        x = self.iddown(x)\n",
    "        #x1 = self.dense(x)\n",
    "        #x.add(x1)\n",
    "        x = self.end(x)\n",
    "        return self.classif(x.view(x.size(0),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #t = Variable(torch.Tensor(8,9,224,224))\n",
    "    #bd = DownBloc(3, 32, 3, nb_frames=3)\n",
    "    #print(bd(t).size())\n",
    "    t = Variable(torch.Tensor(8,9,224,224))\n",
    "    m = DenseMobileF4()\n",
    "    print(m(t).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
